{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jW6HK4wWOpFb"
      },
      "outputs": [],
      "source": [
        "# These lines import the necessary libraries: NumPy for numerical operations, Pandas for data manipulation, and Matplotlib for plotting.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "4q1CxbGlPFG0",
        "outputId": "9a8fb9e0-c1d2-43b8-bff8-1e77d7d941e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>The city had withdrawn into itself\\nAnd left a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>O gift of God! O perfect day:\\n    Whereon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>The world is too much with us; late and soon,\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>To him who in the love of Nature holds\\nCo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>It was an April morning: fresh and clear \\nThe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text\n",
              "0   O my Luve's like a red, red rose\\nThat’s newly...\n",
              "1   The rose is red,\\nThe violet's blue,\\nSugar is...\n",
              "2   How do I love thee? Let me count the ways.\\nI ...\n",
              "3   Had I the heavens' embroidered cloths,\\nEnwrou...\n",
              "4   I.\\n    Enough! we're tired, my heart and I.\\n...\n",
              "..                                                ...\n",
              "95  The city had withdrawn into itself\\nAnd left a...\n",
              "96      O gift of God! O perfect day:\\n    Whereon...\n",
              "97  The world is too much with us; late and soon,\\...\n",
              "98      To him who in the love of Nature holds\\nCo...\n",
              "99  It was an April morning: fresh and clear \\nThe...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reads the 'poems-100.csv' file into a Pandas DataFrame and displays it.\n",
        "df = pd.read_csv(\"poems-100.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YZYiq4yWFC2f"
      },
      "outputs": [],
      "source": [
        "# Joins all text from the first column of the DataFrame into a single string, converts it to lowercase, and splits it into tokens.\n",
        "text = \" \".join(df.iloc[:, 0].astype(str).tolist()).lower()\n",
        "tokens = text.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dJEqWSIJMvJ",
        "outputId": "07599a45-1c99-42c9-bc55-ce4afcfc1925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 6989\n"
          ]
        }
      ],
      "source": [
        "# Creates a sorted vocabulary from the tokens and prints its size.\n",
        "vocab = sorted(set(tokens))\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "D6UA1vZwJN2_"
      },
      "outputs": [],
      "source": [
        "# Creates dictionaries for mapping words to indices and vice-versa.\n",
        "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx_to_word = {i: w for w, i in word_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "u6Q6XAfDJnO3"
      },
      "outputs": [],
      "source": [
        "# Converts the list of word tokens into a list of numerical indices.\n",
        "data = [word_to_idx[word] for word in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5ZlqU66GJrRc"
      },
      "outputs": [],
      "source": [
        "# Sets the hyperparameters for the RNN model.\n",
        "hidden_size = 100\n",
        "seq_length = 5\n",
        "learning_rate = 0.01\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2C10qyJdJr_r"
      },
      "outputs": [],
      "source": [
        "# Initializes the weight matrices and bias vectors for the RNN.\n",
        "Wxh = np.random.randn(hidden_size, vocab_size) * 0.01\n",
        "Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "Why = np.random.randn(vocab_size, hidden_size) * 0.01\n",
        "\n",
        "bh = np.zeros((hidden_size, 1))\n",
        "by = np.zeros((vocab_size, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2H3AAAflJwzP"
      },
      "outputs": [],
      "source": [
        "# Defines the softmax activation function for probability distribution.\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / np.sum(e_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nTdGswN2J0s_"
      },
      "outputs": [],
      "source": [
        "# Defines a one-hot encoding function.\n",
        "def one_hot(idx, size):\n",
        "    vec = np.zeros((size, 1))\n",
        "    vec[idx] = 1\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dsCdqLNmJ1P3"
      },
      "outputs": [],
      "source": [
        "# Defines the loss function for the RNN, including forward and backward passes with gradient clipping.\n",
        "def loss_fun(inputs, targets, hprev):\n",
        "    xs, hs, ys, ps = {}, {}, {}, {}\n",
        "    hs[-1] = np.copy(hprev)\n",
        "    loss = 0\n",
        "\n",
        "    # Forward pass\n",
        "    for t in range(len(inputs)):\n",
        "        xs[t] = one_hot(inputs[t], vocab_size)\n",
        "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh)\n",
        "        ys[t] = np.dot(Why, hs[t]) + by\n",
        "        ps[t] = softmax(ys[t])\n",
        "        loss += -np.log(ps[t][targets[t], 0])\n",
        "\n",
        "    # Backward pass\n",
        "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
        "    dhnext = np.zeros_like(hs[0])\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        dy = np.copy(ps[t])\n",
        "        dy[targets[t]] -= 1\n",
        "\n",
        "        dWhy += np.dot(dy, hs[t].T)\n",
        "        dby += dy\n",
        "\n",
        "        dh = np.dot(Why.T, dy) + dhnext\n",
        "        dhraw = (1 - hs[t] ** 2) * dh\n",
        "\n",
        "        dbh += dhraw\n",
        "        dWxh += np.dot(dhraw, xs[t].T)\n",
        "        dWhh += np.dot(dhraw, hs[t-1].T)\n",
        "\n",
        "        dhnext = np.dot(Whh.T, dhraw)\n",
        "\n",
        "    # Clip gradients\n",
        "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "        np.clip(dparam, -5, 5, out=dparam)\n",
        "\n",
        "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVaDbzfTJ52l",
        "outputId": "4706f7c5-b9ca-4439-f3f1-778e75d87d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 35.8941\n",
            "Epoch 2/50, Loss: 33.9766\n",
            "Epoch 3/50, Loss: 33.3694\n",
            "Epoch 4/50, Loss: 32.7181\n",
            "Epoch 5/50, Loss: 32.0114\n",
            "Epoch 6/50, Loss: 31.3204\n",
            "Epoch 7/50, Loss: 30.6378\n",
            "Epoch 8/50, Loss: 29.9812\n",
            "Epoch 9/50, Loss: 29.3352\n",
            "Epoch 10/50, Loss: 28.7723\n",
            "Epoch 11/50, Loss: 28.2497\n",
            "Epoch 12/50, Loss: 27.8055\n",
            "Epoch 13/50, Loss: 27.3241\n",
            "Epoch 14/50, Loss: 26.8832\n",
            "Epoch 15/50, Loss: 26.5657\n",
            "Epoch 16/50, Loss: 26.2555\n",
            "Epoch 17/50, Loss: 25.8941\n",
            "Epoch 18/50, Loss: 25.5755\n",
            "Epoch 19/50, Loss: 25.2474\n",
            "Epoch 20/50, Loss: 25.1796\n",
            "Epoch 21/50, Loss: 24.9422\n",
            "Epoch 22/50, Loss: 24.6393\n",
            "Epoch 23/50, Loss: 24.4855\n",
            "Epoch 24/50, Loss: 24.3235\n",
            "Epoch 25/50, Loss: 24.2468\n",
            "Epoch 26/50, Loss: 23.9014\n",
            "Epoch 27/50, Loss: 23.7812\n",
            "Epoch 28/50, Loss: 23.5064\n",
            "Epoch 29/50, Loss: 23.6619\n",
            "Epoch 30/50, Loss: 23.2421\n",
            "Epoch 31/50, Loss: 23.3046\n",
            "Epoch 32/50, Loss: 22.9588\n",
            "Epoch 33/50, Loss: 23.3021\n",
            "Epoch 34/50, Loss: 22.8502\n",
            "Epoch 35/50, Loss: 22.7848\n",
            "Epoch 36/50, Loss: 22.6629\n",
            "Epoch 37/50, Loss: 22.6060\n",
            "Epoch 38/50, Loss: 22.7478\n",
            "Epoch 39/50, Loss: 22.8624\n",
            "Epoch 40/50, Loss: 22.7854\n",
            "Epoch 41/50, Loss: 22.6537\n",
            "Epoch 42/50, Loss: 22.6173\n",
            "Epoch 43/50, Loss: 22.7655\n",
            "Epoch 44/50, Loss: 22.7274\n",
            "Epoch 45/50, Loss: 22.6222\n",
            "Epoch 46/50, Loss: 22.7249\n",
            "Epoch 47/50, Loss: 22.5925\n",
            "Epoch 48/50, Loss: 22.6632\n",
            "Epoch 49/50, Loss: 22.6967\n",
            "Epoch 50/50, Loss: 22.8147\n",
            "\n",
            "Training Time: 11621.340609073639 seconds\n"
          ]
        }
      ],
      "source": [
        "# Trains the RNN model using the defined hyperparameters and calculates training time and final loss.\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    p = 0\n",
        "    hprev = np.zeros((hidden_size, 1))\n",
        "    epoch_loss = 0\n",
        "    steps = 0\n",
        "\n",
        "    while p + seq_length + 1 < len(data):\n",
        "\n",
        "        inputs = data[p:p+seq_length]\n",
        "        targets = data[p+1:p+seq_length+1]\n",
        "\n",
        "        loss, dWxh, dWhh, dWhy, dbh, dby, hprev = loss_fun(inputs, targets, hprev)\n",
        "\n",
        "        for param, dparam in zip(\n",
        "            [Wxh, Whh, Why, bh, by],\n",
        "            [dWxh, dWhh, dWhy, dbh, dby]\n",
        "        ):\n",
        "            param -= learning_rate * dparam\n",
        "\n",
        "        epoch_loss += loss\n",
        "        steps += 1\n",
        "        p += seq_length\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / steps\n",
        "    losses.append(avg_epoch_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "scratch_training_time = end_time - start_time\n",
        "scratch_final_loss = losses[-1]\n",
        "\n",
        "print(\"\\nTraining Time:\", scratch_training_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JYwUL0z2UD6Q"
      },
      "outputs": [],
      "source": [
        "# Stores the training results in a Pandas DataFrame and saves it to a CSV file.\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "    \"Model\": \"RNN From Scratch (NumPy)\",\n",
        "    \"Training_Time_Seconds\": scratch_training_time,\n",
        "    \"Final_Loss\": scratch_final_loss\n",
        "    }\n",
        "])\n",
        "\n",
        "df.to_csv(\"scratch_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HIaJ1w3CK3Vm"
      },
      "outputs": [],
      "source": [
        "# Defines a function to generate text from the trained RNN given a seed word and desired length.\n",
        "def generate_text(seed_word, length=20):\n",
        "    h = np.zeros((hidden_size, 1))\n",
        "    x = one_hot(word_to_idx[seed_word], vocab_size)\n",
        "    generated = [seed_word]\n",
        "\n",
        "    for t in range(length):\n",
        "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
        "        y = np.dot(Why, h) + by\n",
        "        p = softmax(y)\n",
        "\n",
        "        idx = np.random.choice(range(vocab_size), p=p.ravel())\n",
        "        word = idx_to_word[idx]\n",
        "\n",
        "        generated.append(word)\n",
        "        x = one_hot(idx, vocab_size)\n",
        "\n",
        "    return \" \".join(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3myY7LulK415",
        "outputId": "cc7a3e3f-1c86-44ed-bd9b-f87cc94e4428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "o the clock where march, though all on, should grow thus certain who work, given and soothed to and clear morning: that have to chamber i sometimes red, and been buckwheat,\n"
          ]
        }
      ],
      "source": [
        "# Calls the 'sample' function to generate 30 words starting with the first token from the original text, and prints the result.\n",
        "print(generate_text(tokens[0], 30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3kxK8ricS-W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
