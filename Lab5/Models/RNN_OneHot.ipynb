{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Pl47I9WlUzyU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gI3FhE0sXFiS"
      },
      "outputs": [],
      "source": [
        "# Load the dataset containing poems from a CSV file into a pandas DataFrame.\n",
        "df = pd.read_csv(\"poems-100.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NfEMajlQXWB8"
      },
      "outputs": [],
      "source": [
        "# Concatenate all poems into a single string, convert to lowercase, and split into individual tokens (words).\n",
        "text = \" \".join(df.iloc[:, 0].astype(str).tolist()).lower()\n",
        "tokens = text.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_KZ13U2XXlP",
        "outputId": "a0c6c199-f354-46c1-fa25-4e3bf4511053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 6989\n"
          ]
        }
      ],
      "source": [
        "# Create a sorted list of unique tokens to form the vocabulary.\n",
        "vocab = sorted(set(tokens))\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Blr4WdITXqWh"
      },
      "outputs": [],
      "source": [
        "# Create mappings from words to their indices and vice-versa for numerical representation.\n",
        "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx_to_word = {i: w for w, i in word_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "v4lrfG-eXsL-"
      },
      "outputs": [],
      "source": [
        "# Define the length of input sequences for the RNN model.\n",
        "sequence_length = 5\n",
        "\n",
        "# Initialize lists to store input sequences and their corresponding target words.\n",
        "inputs = []\n",
        "targets = []\n",
        "\n",
        "# Iterate through the tokens to create input-target pairs.\n",
        "for i in range(len(tokens) - sequence_length):\n",
        "    # Extract a sequence of words as input.\n",
        "    seq = tokens[i:i+sequence_length]\n",
        "    # The word immediately following the sequence is the target.\n",
        "    target = tokens[i+sequence_length]\n",
        "\n",
        "    # Convert words in the input sequence and target word to their numerical indices.\n",
        "    inputs.append([word_to_idx[w] for w in seq])\n",
        "    targets.append(word_to_idx[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "h6rxl4v9X1_R"
      },
      "outputs": [],
      "source": [
        "# Define a function to convert a batch of word indices into one-hot encoded tensors.\n",
        "def one_hot_batch(batch_indices, vocab_size):\n",
        "    # Get batch size and sequence length from the input.\n",
        "    batch_size = len(batch_indices)\n",
        "    seq_len = len(batch_indices[0])\n",
        "\n",
        "    # Initialize a tensor of zeros for one-hot encoding.\n",
        "    one_hot = torch.zeros(batch_size, seq_len, vocab_size)\n",
        "\n",
        "    # Populate the one-hot tensor.\n",
        "    for i in range(batch_size):\n",
        "        for t in range(seq_len):\n",
        "            one_hot[i, t, batch_indices[i][t]] = 1.0\n",
        "\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qlMVxFfyX4OA"
      },
      "outputs": [],
      "source": [
        "# Assign the generated input sequences to X and convert targets to a PyTorch tensor.\n",
        "X = inputs\n",
        "y = torch.tensor(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "mOeGTBkDX7lj"
      },
      "outputs": [],
      "source": [
        "# Define the RNN model for word prediction using one-hot encoding.\n",
        "class RNN_OneHot(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        # Initialize the RNN layer.\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        # Initialize the fully connected layer for output.\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through the RNN layer.\n",
        "        out, _ = self.rnn(x)\n",
        "        # Pass the last hidden state through the fully connected layer.\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eVOwR8uTYOKN"
      },
      "outputs": [],
      "source": [
        "# Define the size of the hidden layer for the RNN.\n",
        "hidden_size = 128\n",
        "# Instantiate the RNN model.\n",
        "model = RNN_OneHot(vocab_size, hidden_size, vocab_size)\n",
        "\n",
        "# Define the loss function (CrossEntropyLoss for classification).\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Define the optimizer (Adam) with a learning rate.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Set the number of training epochs and batch size.\n",
        "epochs = 50\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UycCLzlPYP3j",
        "outputId": "f86fb104-a4cc-4837-e939-980d3e400057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 7.3192\n",
            "Epoch 2/50, Loss: 6.4223\n",
            "Epoch 3/50, Loss: 5.9624\n",
            "Epoch 4/50, Loss: 5.6523\n",
            "Epoch 5/50, Loss: 5.4486\n",
            "Epoch 6/50, Loss: 5.1171\n",
            "Epoch 7/50, Loss: 4.7126\n",
            "Epoch 8/50, Loss: 4.3307\n",
            "Epoch 9/50, Loss: 3.9245\n",
            "Epoch 10/50, Loss: 3.5165\n",
            "Epoch 11/50, Loss: 3.1032\n",
            "Epoch 12/50, Loss: 2.7079\n",
            "Epoch 13/50, Loss: 2.3529\n",
            "Epoch 14/50, Loss: 2.0466\n",
            "Epoch 15/50, Loss: 1.7829\n",
            "Epoch 16/50, Loss: 1.5497\n",
            "Epoch 17/50, Loss: 1.3453\n",
            "Epoch 18/50, Loss: 1.1660\n",
            "Epoch 19/50, Loss: 1.0096\n",
            "Epoch 20/50, Loss: 0.8741\n",
            "Epoch 21/50, Loss: 0.7558\n",
            "Epoch 22/50, Loss: 0.6530\n",
            "Epoch 23/50, Loss: 0.5590\n",
            "Epoch 24/50, Loss: 0.4764\n",
            "Epoch 25/50, Loss: 0.4032\n",
            "Epoch 26/50, Loss: 0.3407\n",
            "Epoch 27/50, Loss: 0.2873\n",
            "Epoch 28/50, Loss: 0.2417\n",
            "Epoch 29/50, Loss: 0.2025\n",
            "Epoch 30/50, Loss: 0.1725\n",
            "Epoch 31/50, Loss: 0.1468\n",
            "Epoch 32/50, Loss: 0.1282\n",
            "Epoch 33/50, Loss: 0.1097\n",
            "Epoch 34/50, Loss: 0.0970\n",
            "Epoch 35/50, Loss: 0.0868\n",
            "Epoch 36/50, Loss: 0.0785\n",
            "Epoch 37/50, Loss: 0.0699\n",
            "Epoch 38/50, Loss: 0.0637\n",
            "Epoch 39/50, Loss: 0.0551\n",
            "Epoch 40/50, Loss: 0.0517\n",
            "Epoch 41/50, Loss: 0.0526\n",
            "Epoch 42/50, Loss: 0.0473\n",
            "Epoch 43/50, Loss: 0.0439\n",
            "Epoch 44/50, Loss: 0.0420\n",
            "Epoch 45/50, Loss: 0.0382\n",
            "Epoch 46/50, Loss: 0.0370\n",
            "Epoch 47/50, Loss: 0.0336\n",
            "Epoch 48/50, Loss: 0.0358\n",
            "Epoch 49/50, Loss: 0.0300\n",
            "Epoch 50/50, Loss: 0.0332\n",
            "\n",
            "Training Time: 257.89110493659973 seconds\n"
          ]
        }
      ],
      "source": [
        "# Initialize a list to store loss values per epoch.\n",
        "losses = []\n",
        "# Record the start time for training duration calculation.\n",
        "start_time = time.time()\n",
        "\n",
        "# Loop through each epoch.\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Iterate through the dataset in batches.\n",
        "    for i in range(0, len(X), batch_size):\n",
        "\n",
        "        # Get the current batch of inputs and targets.\n",
        "        batch_inputs = X[i:i+batch_size]\n",
        "        batch_targets = y[i:i+batch_size]\n",
        "\n",
        "        # Convert batch inputs to one-hot encoding.\n",
        "        batch_onehot = one_hot_batch(batch_inputs, vocab_size)\n",
        "\n",
        "        # Zero the gradients, perform a forward pass, calculate loss, and backpropagate.\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_onehot)\n",
        "        loss = criterion(outputs, batch_targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Calculate the number of batches and average loss for the epoch.\n",
        "    num_batches = (len(X) + batch_size - 1) // batch_size\n",
        "    avg_loss = epoch_loss / num_batches\n",
        "\n",
        "    # Store the average loss.\n",
        "    losses.append(avg_loss)\n",
        "\n",
        "    # Print epoch-wise loss.\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Record the end time and calculate total training duration.\n",
        "end_time = time.time()\n",
        "\n",
        "onehot_training_time = end_time - start_time\n",
        "onehot_final_loss = losses[-1]\n",
        "\n",
        "# Print the total training time.\n",
        "print(\"\\nTraining Time:\", onehot_training_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "hVfK76MfYkOi"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to store the training results for the one-hot encoding model.\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "    \"Model\": \"One-Hot Encoding (PyTorch)\",\n",
        "    \"Training_Time_Seconds\": onehot_training_time,\n",
        "    \"Final_Loss\": onehot_final_loss\n",
        "    }\n",
        "])\n",
        "\n",
        "# Save the results to a CSV file.\n",
        "df.to_csv(\"onehot_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Vp_uTSjNYnjL"
      },
      "outputs": [],
      "source": [
        "# Define a function to generate text using the trained model.\n",
        "def generate_text(start_words, length=20):\n",
        "\n",
        "    # Set the model to evaluation mode.\n",
        "    model.eval()\n",
        "    # Create a copy of the starting words.\n",
        "    words = start_words.copy()\n",
        "\n",
        "    # Generate words one by one up to the specified length.\n",
        "    for _ in range(length):\n",
        "\n",
        "        # Get the last 'sequence_length' words and convert them to indices.\n",
        "        seq = [word_to_idx[w] for w in words[-sequence_length:]]\n",
        "        # Convert the sequence of indices to a one-hot encoded tensor.\n",
        "        seq_tensor = one_hot_batch([seq], vocab_size)\n",
        "\n",
        "        # Make a prediction without tracking gradients.\n",
        "        with torch.no_grad():\n",
        "            output = model(seq_tensor)\n",
        "\n",
        "        # Calculate probabilities and select the word with the highest probability.\n",
        "        probs = torch.softmax(output, dim=1)\n",
        "        next_word_idx = torch.argmax(probs).item()\n",
        "\n",
        "        # Append the predicted word to the list.\n",
        "        words.append(idx_to_word[next_word_idx])\n",
        "\n",
        "    # Join the generated words to form a coherent text.\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhgJjLGMYsPO",
        "outputId": "1b055520-18ca-44fb-de46-4f44a87a59c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "o my luve's like a red, red rose that’s newly sprung in june; o my luve's like the melodie that’s sweetly play'd in tune. as fair art thou, my bonnie lass, so deep in luve\n"
          ]
        }
      ],
      "source": [
        "# Get the initial sequence of words from the beginning of the token list.\n",
        "start = tokens[:sequence_length]\n",
        "# Generate and print text starting with the initial sequence.\n",
        "print(generate_text(start, 30))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
