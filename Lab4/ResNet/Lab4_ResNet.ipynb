{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8bbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425ed4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_cifar = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310ec9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data_path=\"cifar-10-batches-py\", train=True, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        if train:\n",
    "            for i in range(1, 6):\n",
    "                with open(os.path.join(data_path, f\"data_batch_{i}\"), \"rb\") as f:\n",
    "                    batch = pickle.load(f, encoding='bytes')\n",
    "                    self.data.append(batch[b'data'])\n",
    "                    self.labels.extend(batch[b'labels'])\n",
    "            self.data = np.vstack(self.data).astype(np.uint8)\n",
    "        else:\n",
    "            with open(os.path.join(data_path, \"test_batch\"), \"rb\") as f:\n",
    "                batch = pickle.load(f, encoding='bytes')\n",
    "                self.data = batch[b'data'].astype(np.uint8)\n",
    "                self.labels = batch[b'labels']\n",
    "        # convert to HWC\n",
    "        self.data = self.data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def load_cifar10_resnet(data_path=\"cifar-10-batches-py\"):\n",
    "    full_train_dataset = CIFAR10Dataset(\n",
    "        data_path=data_path, train=True, transform=transform_resnet)\n",
    "    train_size = int(0.8 * len(full_train_dataset))\n",
    "    val_size = len(full_train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_train_dataset, [train_size, val_size])\n",
    "    test_dataset = CIFAR10Dataset(\n",
    "        data_path=data_path, train=False, transform=transform_resnet)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "def load_cats_dogs_resnet(folder_path=\"dogs-vs-cats/train\"):\n",
    "    class CatsDogsDataset(Dataset):\n",
    "        def __init__(self, folder_path, transform=None):\n",
    "            self.transform = transform\n",
    "            self.image_paths = []\n",
    "            self.labels = []\n",
    "            for path in glob(os.path.join(folder_path, \"*.jpg\")):\n",
    "                self.image_paths.append(path)\n",
    "                fname = os.path.basename(path).lower()\n",
    "                if \"cat\" in fname:\n",
    "                    self.labels.append(0)\n",
    "                elif \"dog\" in fname:\n",
    "                    self.labels.append(1)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown label in file name: {fname}\")\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "            label = self.labels[idx]\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "\n",
    "    full_dataset = CatsDogsDataset(folder_path, transform=transform_resnet)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_dataset, [train_size, val_size])\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5059824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, activation=\"relu\", input_shape=(3, 32, 32)):\n",
    "        super().__init__()\n",
    "\n",
    "        act = activation.lower()\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU()\n",
    "        elif act == \"tanh\":\n",
    "            self.act = nn.Tanh()\n",
    "        elif act == \"leaky_relu\":\n",
    "            self.act = nn.LeakyReLU()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation\")\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            128 * (input_shape[1] // 8) * (input_shape[2] // 8), 256)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.act(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.act(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.drop(self.act(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cbcebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet18(num_classes, input_size=(224, 224)):\n",
    "    model = models.resnet18(weights=None)\n",
    "    if model.conv1.in_channels != 3:\n",
    "        model.conv1 = nn.Conv2d(3, 64, kernel_size=7,\n",
    "                                stride=2, padding=3, bias=False)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_resnet(model, dataname, train_loader, val_loader, optimizer, criterion, epochs=10, device='cpu'):\n",
    "    model.to(device)\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Val Loss: {val_loss/len(val_loader.dataset):.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            os.makedirs(f\"resnet_models/{dataname}\", exist_ok=True)\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"resnet_models/{dataname}/resnet18_best.pth\")\n",
    "\n",
    "    print(\"Training complete. Best Val Accuracy:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f299dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    running_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = running_loss / total\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a80ff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mz/34p9h3ld08ldtfp6qbl62tmc0000gn/T/ipykernel_45658/1812573342.py:9: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  batch = pickle.load(f, encoding='bytes')\n",
      "/var/folders/mz/34p9h3ld08ldtfp6qbl62tmc0000gn/T/ipykernel_45658/1812573342.py:15: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  batch = pickle.load(f, encoding='bytes')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.3414, Val Loss: 1.1672, Val Acc: 59.29%\n",
      "Epoch 2/10, Train Loss: 0.9058, Val Loss: 0.9468, Val Acc: 66.90%\n",
      "Epoch 3/10, Train Loss: 0.6853, Val Loss: 0.8507, Val Acc: 71.48%\n",
      "Epoch 4/10, Train Loss: 0.5081, Val Loss: 0.7650, Val Acc: 73.51%\n",
      "Epoch 5/10, Train Loss: 0.3389, Val Loss: 0.9067, Val Acc: 71.15%\n",
      "Epoch 6/10, Train Loss: 0.2014, Val Loss: 0.9584, Val Acc: 72.77%\n",
      "Epoch 7/10, Train Loss: 0.1146, Val Loss: 0.9036, Val Acc: 74.18%\n",
      "Epoch 8/10, Train Loss: 0.0775, Val Loss: 0.9485, Val Acc: 73.82%\n",
      "Epoch 9/10, Train Loss: 0.0701, Val Loss: 1.0792, Val Acc: 72.28%\n",
      "Epoch 10/10, Train Loss: 0.0618, Val Loss: 1.0741, Val Acc: 73.50%\n",
      "Training complete. Best Val Accuracy: 74.18\n",
      "Epoch 1/10, Train Loss: 0.5482, Val Loss: 0.4396, Val Acc: 79.44%\n",
      "Epoch 2/10, Train Loss: 0.3881, Val Loss: 0.3817, Val Acc: 82.04%\n",
      "Epoch 3/10, Train Loss: 0.2794, Val Loss: 0.2527, Val Acc: 89.32%\n",
      "Epoch 4/10, Train Loss: 0.1943, Val Loss: 0.2450, Val Acc: 89.22%\n",
      "Epoch 5/10, Train Loss: 0.1251, Val Loss: 0.2551, Val Acc: 90.22%\n",
      "Epoch 6/10, Train Loss: 0.0835, Val Loss: 0.3855, Val Acc: 87.08%\n",
      "Epoch 7/10, Train Loss: 0.0523, Val Loss: 0.4091, Val Acc: 87.46%\n",
      "Epoch 8/10, Train Loss: 0.0519, Val Loss: 0.3702, Val Acc: 88.64%\n",
      "Epoch 9/10, Train Loss: 0.0451, Val Loss: 0.3514, Val Acc: 88.46%\n",
      "Epoch 10/10, Train Loss: 0.0358, Val Loss: 0.4212, Val Acc: 88.52%\n",
      "Training complete. Best Val Accuracy: 90.22\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "cifar_train, cifar_val, cifar_test = load_cifar10_resnet()\n",
    "cifar_trainloader = DataLoader(cifar_train, batch_size=64, shuffle=True)\n",
    "cifar_valloader = DataLoader(cifar_val, batch_size=64, shuffle=False)\n",
    "\n",
    "model_cifar = build_resnet18(num_classes=10)\n",
    "optimizer = optim.Adam(model_cifar.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_resnet(model_cifar, \"cifar\", cifar_trainloader,\n",
    "             cifar_valloader, optimizer, criterion, epochs=10, device=device)\n",
    "\n",
    "dvc_train, dvc_val = load_cats_dogs_resnet()\n",
    "dvc_trainloader = DataLoader(dvc_train, batch_size=32, shuffle=True)\n",
    "dvc_valloader = DataLoader(dvc_val, batch_size=32, shuffle=False)\n",
    "\n",
    "model_dvc = build_resnet18(num_classes=2)\n",
    "optimizer = optim.Adam(model_dvc.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_resnet(model_dvc, \"dvc\", dvc_trainloader, dvc_valloader,\n",
    "             optimizer, criterion, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac3f232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CIFAR-10 model path: models/cifar/model_leaky_relu_random_rmsprop_best.pth\n",
      "Best Dogs vs Cats model path: models/dvc/model_leaky_relu_kaiming_adam_best.pth\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_csv('experiment_results.csv'))\n",
    "best_cifar = df[df.dataset == \"Cifar-10\"].nlargest(1, \"accuracy\")\n",
    "best_dvc = df[df.dataset == \"Dogs vs Cats\"].nlargest(1, \"accuracy\")\n",
    "\n",
    "best_cifar_model_path = f\"models/cifar/model_{best_cifar.iloc[0]['activation']}_{best_cifar.iloc[0]['init']}_{best_cifar.iloc[0]['optimizer']}_best.pth\"\n",
    "best_dvc_model_path = f\"models/dvc/model_{best_dvc.iloc[0]['activation']}_{best_dvc.iloc[0]['init']}_{best_dvc.iloc[0]['optimizer']}_best.pth\"\n",
    "\n",
    "print(\"Best CIFAR-10 model path:\", best_cifar_model_path)\n",
    "print(\"Best Dogs vs Cats model path:\", best_dvc_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77384ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison saved to comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "results = []\n",
    "\n",
    "resnet_model = build_resnet18(num_classes=10)\n",
    "resnet_model.load_state_dict(torch.load(\n",
    "    \"resnet_models/cifar/resnet18_best.pth\", map_location=device))\n",
    "resnet_acc, resnet_loss = evaluate_model(\n",
    "    resnet_model, cifar_valloader, criterion, device)\n",
    "results.append({\n",
    "    'dataset': 'CIFAR-10',\n",
    "    'model': 'ResNet-18',\n",
    "    'accuracy': resnet_acc,\n",
    "    'loss': resnet_loss\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'dataset': 'CIFAR-10',\n",
    "    'model': f\"{best_cifar.iloc[0]['activation']}_{best_cifar.iloc[0]['init']}_{best_cifar.iloc[0]['optimizer']}\",\n",
    "    'accuracy': best_cifar.iloc[0]['accuracy'],\n",
    "    'loss': best_cifar.iloc[0]['val_loss']\n",
    "})\n",
    "\n",
    "resnet_model = build_resnet18(num_classes=2)\n",
    "resnet_model.load_state_dict(torch.load(\n",
    "    \"resnet_models/dvc/resnet18_best.pth\", map_location=device))\n",
    "resnet_acc, resnet_loss = evaluate_model(\n",
    "    resnet_model, dvc_valloader, criterion, device)\n",
    "results.append({\n",
    "    'dataset': 'Dogs vs Cats',\n",
    "    'model': 'ResNet-18',\n",
    "    'accuracy': resnet_acc,\n",
    "    'loss': resnet_loss\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'dataset': 'Dogs vs Cats',\n",
    "    'model': f\"{best_dvc.iloc[0]['activation']}_{best_dvc.iloc[0]['init']}_{best_dvc.iloc[0]['optimizer']}\",\n",
    "    'accuracy': best_dvc.iloc[0]['accuracy'],\n",
    "    'loss': best_dvc.iloc[0]['val_loss']\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"comparison_results.csv\", index=False)\n",
    "print(\"Comparison saved to comparison_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98c9b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIFAR-10</td>\n",
       "      <td>ResNet-18</td>\n",
       "      <td>74.18</td>\n",
       "      <td>0.903581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIFAR-10</td>\n",
       "      <td>leaky_relu_random_rmsprop</td>\n",
       "      <td>84.03</td>\n",
       "      <td>0.463258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dogs vs Cats</td>\n",
       "      <td>ResNet-18</td>\n",
       "      <td>90.22</td>\n",
       "      <td>0.255094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dogs vs Cats</td>\n",
       "      <td>leaky_relu_kaiming_adam</td>\n",
       "      <td>89.74</td>\n",
       "      <td>0.234952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset                      model  accuracy      loss\n",
       "0      CIFAR-10                  ResNet-18     74.18  0.903581\n",
       "1      CIFAR-10  leaky_relu_random_rmsprop     84.03  0.463258\n",
       "2  Dogs vs Cats                  ResNet-18     90.22  0.255094\n",
       "3  Dogs vs Cats    leaky_relu_kaiming_adam     89.74  0.234952"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_csv('comparison_results.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ad58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
